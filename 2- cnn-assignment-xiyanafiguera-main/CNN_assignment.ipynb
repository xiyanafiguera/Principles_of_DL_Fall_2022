{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q98UeUjRdyG9"
      },
      "source": [
        "# Image Classification with Convolution Neural Network (CNN) Assignment\n",
        "\n",
        "1. Construct Kaggle Dataset \n",
        "2. Construct a simple CNN\n",
        "3. Set hyperparameters (optimizer, criterion, num epochs)\n",
        "4. Write train / validate code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CpJVmq7T1RNr"
      },
      "outputs": [],
      "source": [
        "# Import libraries to use for Deep Learning \n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.io import read_image\n",
        "from torchsummary import summary\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os \n",
        "\n",
        "import cv2 as cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yV-6tSNBwzBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068a0fbe-2fbb-47e2-e442-ab87c2626807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Access denied with the following error:\n",
            "\n",
            " \tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1rctM1HDoc24XOcRzsYyTSavaFrvuoKZc \n",
            "\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown && gdown 'https://drive.google.com/uc?id=1rctM1HDoc24XOcRzsYyTSavaFrvuoKZc' && unzip ./archive.zip -d ./sports\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#!unzip \"/content/drive/MyDrive/archive.zip\" -d \"/content/drive/MyDrive/sports\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9counoSleNDc"
      },
      "source": [
        "#1. (Assignment) Construct Kaggle Dataset\n",
        "\n",
        "- Please construct custom dataset dealt in the class.\n",
        "- Do not use `torch.utils.data.ImageFolder`.\n",
        "- The structure of Custom Dataset follows \n",
        "- Tips) use `sports.csv` files to get data. (it contains filepath, labels and which dataset each data belongs to)\n",
        "- Tips) use `class_dict.csv` to get the index of each class - numeric values, not string.\n",
        "- Tips) there are some grayscale (1-channel) images. I recommend to use `cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)` to make it 3-channel image.\n",
        "\n",
        "```\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    # Inherit torch.utils.data.Dataset class\n",
        "\n",
        "    def __init__(self,):\n",
        "        # Initialize the dataset (handling data paths, check input and target data, data augmentation, etc.)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of data or sample in dataset \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Return the input and target by index\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I3uMdcUBshYg"
      },
      "outputs": [],
      "source": [
        "### PLEASE WRITE YOUR CODE BELOW.\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self,root_dir,img_file,class_file,data,transform=None):\n",
        "        # Initialize the dataset (handling data paths, check input and target data, data augmentation, etc.)\n",
        "        self.root_dir = root_dir\n",
        "        self.classes = pd.read_csv(class_file)\n",
        "        self.sports_file = pd.read_csv(img_file)\n",
        "        self.images_train_file = self.sports_file[self.sports_file[\"data set\"]==data]        \n",
        "        self.transform = transform \n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of data or sample in dataset \n",
        "        return len(self.images_train_file) \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Return the input and target by index\n",
        "        img_path = os.path.join(self.root_dir, self.images_train_file.iloc[index, 0])        \n",
        "        img_label = self.images_train_file.iloc[index, 1]\n",
        "        row = self.classes.loc[self.classes['class'] == img_label]\n",
        "        label = torch.tensor(row[\"class_index\"].values[0])        \n",
        "        image = Image.open(img_path).convert('RGB')      \n",
        "                \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return (image,label)\n",
        "        \n",
        "### END OF THE CODE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DFe-GEJfAabt"
      },
      "outputs": [],
      "source": [
        "### PLEASE WRITE YOUR CODE BELOW.\n",
        "\n",
        "train_dataset = CustomDataset(\n",
        "    root_dir = '/content/drive/MyDrive/sports/',\n",
        "    img_file='/content/drive/MyDrive/sports/sports.csv',\n",
        "    class_file='/content/drive/MyDrive/sports/class_dict.csv',\n",
        "    data=\"train\",\n",
        "    transform=transforms.ToTensor(),\n",
        "    \n",
        ")\n",
        "valid_dataset = CustomDataset(\n",
        "    root_dir = '/content/drive/MyDrive/sports/',\n",
        "    img_file='/content/drive/MyDrive/sports/sports.csv',\n",
        "    class_file='/content/drive/MyDrive/sports/class_dict.csv',\n",
        "    data=\"valid\",\n",
        "    transform=transforms.ToTensor(),\n",
        "    \n",
        ")\n",
        "test_dataset = CustomDataset(\n",
        "    root_dir = '/content/drive/MyDrive/sports/',\n",
        "    img_file='/content/drive/MyDrive/sports/sports.csv',\n",
        "    class_file='/content/drive/MyDrive/sports/class_dict.csv',\n",
        "    data=\"test\",\n",
        "    transform=transforms.ToTensor(),\n",
        "    \n",
        ")\n",
        "### YOU CAN USE ANY TRANSFORMS YOU WANT. MAKE IT RUNNABLE!\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "### END OF THE CODE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpsxtveWl-bb"
      },
      "source": [
        "##2. (Assignment) Construct a network - Simple CNN\n",
        "\n",
        "- Please construct 4 convolution blocks with following sequences.\n",
        "\n",
        "\n",
        "```\n",
        "first layer = [2D Conv -> BatchNorm -> ReLU -> Dropout -> Pooling]\n",
        "\n",
        "- 2D Convolution with 3x3 kernel size, returns output dimension of 16, use stride and padding = 1.\n",
        "- use whatever pooling you want with 2x2 kernel size and stride of 2.\n",
        "\n",
        "second layer = [2D Conv -> BatchNorm -> ReLU -> Dropout -> Pooling]\n",
        "\n",
        "- 2D Convolution with 3x3 kernel size, returns output dimension of 32, use stride and padding = 1.\n",
        "- use whatever pooling you want with 2x2 kernel size and stride of 2.\n",
        "\n",
        "thrid layer = [2D Conv -> BatchNorm -> ReLU -> Dropout -> Pooling]\n",
        "\n",
        "- 2D Convolution with 3x3 kernel size, returns output dimension of 64, use stride and padding = 1.\n",
        "- use whatever pooling you want with 2x2 kernel size and stride of 2.\n",
        "\n",
        "fourth layer = [2D Conv -> BatchNorm -> ReLU -> Dropout -> Pooling]\n",
        "\n",
        "- 2D Convolution with 3x3 kernel size, returns output dimension of 128, use stride and padding = 1.\n",
        "- use whatever pooling you want with 2x2 kernel size and stride of 2.\n",
        "\n",
        "classifier = [Linear -> ReLU -> Linear]\n",
        "\n",
        "- flatten the output tensor.\n",
        "- first linear layer returns output dimension of 5012\n",
        "- second linear layer returns output dimension of number of classes\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3-HboBkFhDaB"
      },
      "outputs": [],
      "source": [
        "### PLEASE WRITE YOUR CODE BELOW.\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3,\n",
        "                               stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3,\n",
        "                               stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,\n",
        "                               stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3,\n",
        "                               stride=1, padding=1)\n",
        "        \n",
        "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=16)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
        "        self.bn3 = nn.BatchNorm2d(num_features=64)\n",
        "        self.bn4 = nn.BatchNorm2d(num_features=128)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        self.linear = nn.Linear(in_features=128*14*14, out_features=5012)\n",
        "        self.classifier = nn.Linear(in_features=5012, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.avg_pool(self.dropout(self.activation(self.bn1(self.conv1(x)))))\n",
        "        out = self.avg_pool(self.dropout(self.activation(self.bn2(self.conv2(out)))))\n",
        "        out = self.avg_pool(self.dropout(self.activation(self.bn3(self.conv3(out)))))\n",
        "        out = self.avg_pool(self.dropout(self.activation(self.bn4(self.conv4(out)))))\n",
        "\n",
        "        out = out.view(out.size(0), -1)        \n",
        "\n",
        "        out = self.linear(out)\n",
        "        out = self.activation(out)\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "### END OF THE CODE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5VYxN3gSlCJ",
        "outputId": "fdae41f0-6770-4d51-99f0-475289fff681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]             448\n",
            "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
            "              ReLU-3         [-1, 16, 224, 224]               0\n",
            "           Dropout-4         [-1, 16, 224, 224]               0\n",
            "         AvgPool2d-5         [-1, 16, 112, 112]               0\n",
            "            Conv2d-6         [-1, 32, 112, 112]           4,640\n",
            "       BatchNorm2d-7         [-1, 32, 112, 112]              64\n",
            "              ReLU-8         [-1, 32, 112, 112]               0\n",
            "           Dropout-9         [-1, 32, 112, 112]               0\n",
            "        AvgPool2d-10           [-1, 32, 56, 56]               0\n",
            "           Conv2d-11           [-1, 64, 56, 56]          18,496\n",
            "      BatchNorm2d-12           [-1, 64, 56, 56]             128\n",
            "             ReLU-13           [-1, 64, 56, 56]               0\n",
            "          Dropout-14           [-1, 64, 56, 56]               0\n",
            "        AvgPool2d-15           [-1, 64, 28, 28]               0\n",
            "           Conv2d-16          [-1, 128, 28, 28]          73,856\n",
            "      BatchNorm2d-17          [-1, 128, 28, 28]             256\n",
            "             ReLU-18          [-1, 128, 28, 28]               0\n",
            "          Dropout-19          [-1, 128, 28, 28]               0\n",
            "        AvgPool2d-20          [-1, 128, 14, 14]               0\n",
            "           Linear-21                 [-1, 5012]     125,746,068\n",
            "             ReLU-22                 [-1, 5012]               0\n",
            "           Linear-23                  [-1, 100]         501,300\n",
            "================================================================\n",
            "Total params: 126,345,288\n",
            "Trainable params: 126,345,288\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 48.89\n",
            "Params size (MB): 481.97\n",
            "Estimated Total Size (MB): 531.43\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = SimpleCNN(in_channels=3, num_classes=100).cuda()\n",
        "summary(model, (3, 224, 224), device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj3281v__AlY"
      },
      "source": [
        "##3. (Assignment) Set hyperparameters\n",
        "\n",
        "- Set the total number of epochs to be 50 and the learning rate to be 0.001.\n",
        "\n",
        "- Use any optimizers you want. Please refer [here](https://pytorch.org/docs/stable/optim.html) for furter details.\n",
        "    - Remember different optimizers have different hyperparameters.\n",
        "- Set the loss function to be cross entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8pCDa2YK4fqv"
      },
      "outputs": [],
      "source": [
        "### PLEASE FILL OUT THE HYPERPARAMETERS\n",
        "### NOTE THAT YOU SHOULD SET DIFFERENT PARAMETERS FOR DIFFERENT OPTIMIZERS.\n",
        "\n",
        "lr = 0.001\n",
        "epochs = 50\n",
        "\n",
        "## OPTIMIZER HYPERPARAMETERS - PLEASE ADD/REMOVE DEPENDS ON OPTIMIZER.\n",
        "betas = (0.9, 0.999)\n",
        "momentum = None\n",
        "\n",
        "## WHEN USING GPU, PUT `.cuda()` on model and criterion.\n",
        "\n",
        "model = SimpleCNN(in_channels=3, num_classes=100).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
        "criterion = nn.CrossEntropyLoss().cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS29-fIf4jrq"
      },
      "source": [
        "##4. (Assignment) Write train / validation code\n",
        "\n",
        "- For each epoch, we train and validate the model.\n",
        "- Note that the validation dataset is not included in test set. \n",
        "- Please refer to the following procedure:\n",
        "\n",
        "\n",
        "    for each epoch:\n",
        "        model.train()\n",
        "        get input and target data from train loader\n",
        "        \n",
        "        optmizer.zero_grad()             # reset the gradient \n",
        "        pred = model(input)\n",
        "\n",
        "        loss = criterion(pred, target)   # compute the loss\n",
        "        loss.backward()                  # backprop\n",
        "        optimizer.step()                 # update the model weights\n",
        "\n",
        "        model.eval()                     # set the evaluation mode (turn off batchnorm, dropout)\n",
        "        with torch.no_grad():\n",
        "            get the input and target data from validation loader\n",
        "\n",
        "            pred = model(input)\n",
        "            compute the validation loss  # Optional \n",
        "            calculate the validation accuracy\n",
        "            save the model w.r.t. validation accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TeRQcYZ951WH"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, data_loader, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for idx, batch in enumerate(data_loader):\n",
        "        img, target = batch[0].cuda(), batch[1].cuda()\n",
        "\n",
        "        ### PLEASE WRITE YOUR CODE BELOW.\n",
        "        # Initialize the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make a prediction\n",
        "        output = model(img)\n",
        "\n",
        "        # Calculate loss with prediction and target\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Compute the gradient\n",
        "        loss.backward()\n",
        "\n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        ### END OF THE CODE.\n",
        "\n",
        "        total_loss += loss.item() \n",
        "\n",
        "        if idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch + 1, idx * img.size(0), len(data_loader.dataset),\n",
        "                100. * idx * img.size(0) / len(data_loader.dataset), \n",
        "                loss.data))\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "def validate(model, criterion, data_loader):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(data_loader):\n",
        "            img, target = batch[0].cuda(), batch[1].cuda()\n",
        "\n",
        "            ### PLEASE WRITE YOUR CODE BELOW.\n",
        "\n",
        "            # Make a prediction\n",
        "            output = model(img)\n",
        "\n",
        "            # Calculate validation loss (although it is optional)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # Get the right prediction - make sure naming the prediction as 'predicted'\n",
        "            _, predicted = torch.max(output.data, 1) \n",
        "\n",
        "            ### END OF THE CODE.\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_acc += (predicted == target).sum().item()\n",
        "\n",
        "        total_val_acc = val_acc / len(data_loader.dataset)\n",
        "        print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            val_loss / len(data_loader), val_acc, len(data_loader.dataset),\n",
        "            100. * total_val_acc))\n",
        "    \n",
        "    return total_val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PE6MMpqVzpKH"
      },
      "outputs": [],
      "source": [
        "def test(model, data_loader):\n",
        "    model.eval()\n",
        "    test_acc = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(data_loader):\n",
        "            img, target = batch[0].cuda(), batch[1].cuda()\n",
        "\n",
        "            ### PLEASE WRITE YOUR CODE BELOW.\n",
        "\n",
        "            # Make a prediction\n",
        "            output = model(img)\n",
        "\n",
        "            # Calculate validation loss (although it is optional)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # Get the right prediction - make sure naming the prediction as 'predicted'\n",
        "            _, predicted = torch.max(output.data, 1) \n",
        "            test_acc += (predicted == target).sum().item() \n",
        "\n",
        "            ### END OF THE CODE.\n",
        "\n",
        "        print('\\n Test set:  Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_acc, len(data_loader.dataset),\n",
        "            100. * test_acc / len(data_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5EaA6sGo2b3",
        "outputId": "4b6b130c-ed70-46a5-e640-7fb62fe90b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/13572 (0%)]\tLoss: 4.605180\n",
            "Train Epoch: 1 [1280/13572 (9%)]\tLoss: 21.087706\n",
            "Train Epoch: 1 [2560/13572 (19%)]\tLoss: 10.954556\n",
            "Train Epoch: 1 [3840/13572 (28%)]\tLoss: 4.854076\n",
            "Train Epoch: 1 [5120/13572 (38%)]\tLoss: 4.582865\n",
            "Train Epoch: 1 [6400/13572 (47%)]\tLoss: 4.537932\n",
            "Train Epoch: 1 [7680/13572 (57%)]\tLoss: 4.522333\n",
            "Train Epoch: 1 [8960/13572 (66%)]\tLoss: 4.415493\n",
            "Train Epoch: 1 [10240/13572 (75%)]\tLoss: 4.427828\n",
            "Train Epoch: 1 [11520/13572 (85%)]\tLoss: 4.214763\n",
            "Train Epoch: 1 [12800/13572 (94%)]\tLoss: 4.276807\n",
            "\n",
            "Validation set: Average loss: 4.3078, Accuracy: 16.0/500 (3%)\n",
            "\n",
            "Train Epoch: 2 [0/13572 (0%)]\tLoss: 4.215328\n",
            "Train Epoch: 2 [1280/13572 (9%)]\tLoss: 4.195678\n",
            "Train Epoch: 2 [2560/13572 (19%)]\tLoss: 4.144504\n",
            "Train Epoch: 2 [3840/13572 (28%)]\tLoss: 4.038472\n",
            "Train Epoch: 2 [5120/13572 (38%)]\tLoss: 4.105844\n",
            "Train Epoch: 2 [6400/13572 (47%)]\tLoss: 4.084499\n",
            "Train Epoch: 2 [7680/13572 (57%)]\tLoss: 4.108316\n",
            "Train Epoch: 2 [8960/13572 (66%)]\tLoss: 3.816010\n",
            "Train Epoch: 2 [10240/13572 (75%)]\tLoss: 3.972656\n",
            "Train Epoch: 2 [11520/13572 (85%)]\tLoss: 3.783420\n",
            "Train Epoch: 2 [12800/13572 (94%)]\tLoss: 3.862801\n",
            "\n",
            "Validation set: Average loss: 3.8555, Accuracy: 39.0/500 (8%)\n",
            "\n",
            "Train Epoch: 3 [0/13572 (0%)]\tLoss: 3.626470\n",
            "Train Epoch: 3 [1280/13572 (9%)]\tLoss: 3.827322\n",
            "Train Epoch: 3 [2560/13572 (19%)]\tLoss: 3.679181\n",
            "Train Epoch: 3 [3840/13572 (28%)]\tLoss: 3.663995\n",
            "Train Epoch: 3 [5120/13572 (38%)]\tLoss: 3.765201\n",
            "Train Epoch: 3 [6400/13572 (47%)]\tLoss: 3.609606\n",
            "Train Epoch: 3 [7680/13572 (57%)]\tLoss: 3.716498\n",
            "Train Epoch: 3 [8960/13572 (66%)]\tLoss: 3.566519\n",
            "Train Epoch: 3 [10240/13572 (75%)]\tLoss: 3.552283\n",
            "Train Epoch: 3 [11520/13572 (85%)]\tLoss: 3.768193\n",
            "Train Epoch: 3 [12800/13572 (94%)]\tLoss: 3.708059\n",
            "\n",
            "Validation set: Average loss: 3.5665, Accuracy: 62.0/500 (12%)\n",
            "\n",
            "Train Epoch: 4 [0/13572 (0%)]\tLoss: 3.546085\n",
            "Train Epoch: 4 [1280/13572 (9%)]\tLoss: 3.523254\n",
            "Train Epoch: 4 [2560/13572 (19%)]\tLoss: 3.399207\n",
            "Train Epoch: 4 [3840/13572 (28%)]\tLoss: 3.354730\n",
            "Train Epoch: 4 [5120/13572 (38%)]\tLoss: 3.412144\n",
            "Train Epoch: 4 [6400/13572 (47%)]\tLoss: 3.283239\n",
            "Train Epoch: 4 [7680/13572 (57%)]\tLoss: 3.459229\n",
            "Train Epoch: 4 [8960/13572 (66%)]\tLoss: 3.310565\n",
            "Train Epoch: 4 [10240/13572 (75%)]\tLoss: 3.457889\n",
            "Train Epoch: 4 [11520/13572 (85%)]\tLoss: 3.336281\n",
            "Train Epoch: 4 [12800/13572 (94%)]\tLoss: 3.181827\n",
            "\n",
            "Validation set: Average loss: 3.3565, Accuracy: 74.0/500 (15%)\n",
            "\n",
            "Train Epoch: 5 [0/13572 (0%)]\tLoss: 3.147410\n",
            "Train Epoch: 5 [1280/13572 (9%)]\tLoss: 3.304194\n",
            "Train Epoch: 5 [2560/13572 (19%)]\tLoss: 3.396102\n",
            "Train Epoch: 5 [3840/13572 (28%)]\tLoss: 3.053292\n",
            "Train Epoch: 5 [5120/13572 (38%)]\tLoss: 3.205642\n",
            "Train Epoch: 5 [6400/13572 (47%)]\tLoss: 3.195343\n",
            "Train Epoch: 5 [7680/13572 (57%)]\tLoss: 3.036826\n",
            "Train Epoch: 5 [8960/13572 (66%)]\tLoss: 2.885733\n",
            "Train Epoch: 5 [10240/13572 (75%)]\tLoss: 3.262317\n",
            "Train Epoch: 5 [11520/13572 (85%)]\tLoss: 3.045877\n",
            "Train Epoch: 5 [12800/13572 (94%)]\tLoss: 2.861380\n",
            "\n",
            "Validation set: Average loss: 3.1399, Accuracy: 105.0/500 (21%)\n",
            "\n",
            "Train Epoch: 6 [0/13572 (0%)]\tLoss: 3.073288\n",
            "Train Epoch: 6 [1280/13572 (9%)]\tLoss: 2.918828\n",
            "Train Epoch: 6 [2560/13572 (19%)]\tLoss: 3.083866\n",
            "Train Epoch: 6 [3840/13572 (28%)]\tLoss: 3.024091\n",
            "Train Epoch: 6 [5120/13572 (38%)]\tLoss: 3.041545\n",
            "Train Epoch: 6 [6400/13572 (47%)]\tLoss: 3.071013\n",
            "Train Epoch: 6 [7680/13572 (57%)]\tLoss: 2.817398\n",
            "Train Epoch: 6 [8960/13572 (66%)]\tLoss: 2.811738\n",
            "Train Epoch: 6 [10240/13572 (75%)]\tLoss: 2.988620\n",
            "Train Epoch: 6 [11520/13572 (85%)]\tLoss: 2.984589\n",
            "Train Epoch: 6 [12800/13572 (94%)]\tLoss: 2.869026\n",
            "\n",
            "Validation set: Average loss: 3.3707, Accuracy: 105.0/500 (21%)\n",
            "\n",
            "Train Epoch: 7 [0/13572 (0%)]\tLoss: 2.637566\n",
            "Train Epoch: 7 [1280/13572 (9%)]\tLoss: 2.791971\n",
            "Train Epoch: 7 [2560/13572 (19%)]\tLoss: 2.781991\n",
            "Train Epoch: 7 [3840/13572 (28%)]\tLoss: 2.713742\n",
            "Train Epoch: 7 [5120/13572 (38%)]\tLoss: 2.727924\n",
            "Train Epoch: 7 [6400/13572 (47%)]\tLoss: 2.700581\n",
            "Train Epoch: 7 [7680/13572 (57%)]\tLoss: 2.752745\n",
            "Train Epoch: 7 [8960/13572 (66%)]\tLoss: 2.784706\n",
            "Train Epoch: 7 [10240/13572 (75%)]\tLoss: 2.590705\n",
            "Train Epoch: 7 [11520/13572 (85%)]\tLoss: 2.755829\n",
            "Train Epoch: 7 [12800/13572 (94%)]\tLoss: 2.690347\n",
            "\n",
            "Validation set: Average loss: 2.9310, Accuracy: 127.0/500 (25%)\n",
            "\n",
            "Train Epoch: 8 [0/13572 (0%)]\tLoss: 2.695524\n",
            "Train Epoch: 8 [1280/13572 (9%)]\tLoss: 2.965208\n",
            "Train Epoch: 8 [2560/13572 (19%)]\tLoss: 2.677742\n",
            "Train Epoch: 8 [3840/13572 (28%)]\tLoss: 2.423370\n",
            "Train Epoch: 8 [5120/13572 (38%)]\tLoss: 2.570247\n",
            "Train Epoch: 8 [6400/13572 (47%)]\tLoss: 2.482824\n",
            "Train Epoch: 8 [7680/13572 (57%)]\tLoss: 2.419467\n",
            "Train Epoch: 8 [8960/13572 (66%)]\tLoss: 2.492305\n",
            "Train Epoch: 8 [10240/13572 (75%)]\tLoss: 2.367643\n",
            "Train Epoch: 8 [11520/13572 (85%)]\tLoss: 2.481823\n",
            "Train Epoch: 8 [12800/13572 (94%)]\tLoss: 2.311038\n",
            "\n",
            "Validation set: Average loss: 2.7146, Accuracy: 155.0/500 (31%)\n",
            "\n",
            "Train Epoch: 9 [0/13572 (0%)]\tLoss: 2.327605\n",
            "Train Epoch: 9 [1280/13572 (9%)]\tLoss: 2.198915\n",
            "Train Epoch: 9 [2560/13572 (19%)]\tLoss: 2.133675\n",
            "Train Epoch: 9 [3840/13572 (28%)]\tLoss: 2.561113\n",
            "Train Epoch: 9 [5120/13572 (38%)]\tLoss: 2.268341\n",
            "Train Epoch: 9 [6400/13572 (47%)]\tLoss: 2.374292\n",
            "Train Epoch: 9 [7680/13572 (57%)]\tLoss: 2.487836\n",
            "Train Epoch: 9 [8960/13572 (66%)]\tLoss: 2.564367\n",
            "Train Epoch: 9 [10240/13572 (75%)]\tLoss: 2.295828\n",
            "Train Epoch: 9 [11520/13572 (85%)]\tLoss: 2.402444\n",
            "Train Epoch: 9 [12800/13572 (94%)]\tLoss: 2.222487\n",
            "\n",
            "Validation set: Average loss: 2.6912, Accuracy: 156.0/500 (31%)\n",
            "\n",
            "Train Epoch: 10 [0/13572 (0%)]\tLoss: 2.118635\n",
            "Train Epoch: 10 [1280/13572 (9%)]\tLoss: 2.345203\n",
            "Train Epoch: 10 [2560/13572 (19%)]\tLoss: 2.412457\n",
            "Train Epoch: 10 [3840/13572 (28%)]\tLoss: 2.446296\n",
            "Train Epoch: 10 [5120/13572 (38%)]\tLoss: 2.224482\n",
            "Train Epoch: 10 [6400/13572 (47%)]\tLoss: 2.087406\n",
            "Train Epoch: 10 [7680/13572 (57%)]\tLoss: 2.203823\n",
            "Train Epoch: 10 [8960/13572 (66%)]\tLoss: 2.050007\n",
            "Train Epoch: 10 [10240/13572 (75%)]\tLoss: 2.171029\n",
            "Train Epoch: 10 [11520/13572 (85%)]\tLoss: 2.406893\n",
            "Train Epoch: 10 [12800/13572 (94%)]\tLoss: 2.034543\n",
            "\n",
            "Validation set: Average loss: 2.5712, Accuracy: 168.0/500 (34%)\n",
            "\n",
            "Train Epoch: 11 [0/13572 (0%)]\tLoss: 1.984048\n",
            "Train Epoch: 11 [1280/13572 (9%)]\tLoss: 2.157719\n",
            "Train Epoch: 11 [2560/13572 (19%)]\tLoss: 2.127678\n",
            "Train Epoch: 11 [3840/13572 (28%)]\tLoss: 2.024300\n",
            "Train Epoch: 11 [5120/13572 (38%)]\tLoss: 1.990413\n",
            "Train Epoch: 11 [6400/13572 (47%)]\tLoss: 2.036756\n",
            "Train Epoch: 11 [7680/13572 (57%)]\tLoss: 1.962487\n",
            "Train Epoch: 11 [8960/13572 (66%)]\tLoss: 2.230623\n",
            "Train Epoch: 11 [10240/13572 (75%)]\tLoss: 2.153861\n",
            "Train Epoch: 11 [11520/13572 (85%)]\tLoss: 2.265567\n",
            "Train Epoch: 11 [12800/13572 (94%)]\tLoss: 1.917903\n",
            "\n",
            "Validation set: Average loss: 2.5948, Accuracy: 184.0/500 (37%)\n",
            "\n",
            "Train Epoch: 12 [0/13572 (0%)]\tLoss: 1.861039\n",
            "Train Epoch: 12 [1280/13572 (9%)]\tLoss: 2.054343\n",
            "Train Epoch: 12 [2560/13572 (19%)]\tLoss: 1.802593\n",
            "Train Epoch: 12 [3840/13572 (28%)]\tLoss: 2.008750\n",
            "Train Epoch: 12 [5120/13572 (38%)]\tLoss: 1.831305\n",
            "Train Epoch: 12 [6400/13572 (47%)]\tLoss: 2.063904\n",
            "Train Epoch: 12 [7680/13572 (57%)]\tLoss: 2.173534\n",
            "Train Epoch: 12 [8960/13572 (66%)]\tLoss: 1.898100\n",
            "Train Epoch: 12 [10240/13572 (75%)]\tLoss: 2.033224\n",
            "Train Epoch: 12 [11520/13572 (85%)]\tLoss: 2.137551\n",
            "Train Epoch: 12 [12800/13572 (94%)]\tLoss: 1.873519\n",
            "\n",
            "Validation set: Average loss: 2.6672, Accuracy: 171.0/500 (34%)\n",
            "\n",
            "Train Epoch: 13 [0/13572 (0%)]\tLoss: 1.606605\n",
            "Train Epoch: 13 [1280/13572 (9%)]\tLoss: 1.815590\n",
            "Train Epoch: 13 [2560/13572 (19%)]\tLoss: 1.977951\n",
            "Train Epoch: 13 [3840/13572 (28%)]\tLoss: 1.800976\n",
            "Train Epoch: 13 [5120/13572 (38%)]\tLoss: 1.839277\n",
            "Train Epoch: 13 [6400/13572 (47%)]\tLoss: 1.882876\n",
            "Train Epoch: 13 [7680/13572 (57%)]\tLoss: 2.083301\n",
            "Train Epoch: 13 [8960/13572 (66%)]\tLoss: 1.928728\n",
            "Train Epoch: 13 [10240/13572 (75%)]\tLoss: 2.087431\n",
            "Train Epoch: 13 [11520/13572 (85%)]\tLoss: 1.972747\n",
            "Train Epoch: 13 [12800/13572 (94%)]\tLoss: 1.921939\n",
            "\n",
            "Validation set: Average loss: 2.8663, Accuracy: 160.0/500 (32%)\n",
            "\n",
            "Train Epoch: 14 [0/13572 (0%)]\tLoss: 1.699227\n",
            "Train Epoch: 14 [1280/13572 (9%)]\tLoss: 2.318546\n",
            "Train Epoch: 14 [2560/13572 (19%)]\tLoss: 1.875066\n",
            "Train Epoch: 14 [3840/13572 (28%)]\tLoss: 1.868936\n",
            "Train Epoch: 14 [5120/13572 (38%)]\tLoss: 1.899772\n",
            "Train Epoch: 14 [6400/13572 (47%)]\tLoss: 1.631589\n",
            "Train Epoch: 14 [7680/13572 (57%)]\tLoss: 1.789758\n",
            "Train Epoch: 14 [8960/13572 (66%)]\tLoss: 1.678672\n",
            "Train Epoch: 14 [10240/13572 (75%)]\tLoss: 1.745982\n",
            "Train Epoch: 14 [11520/13572 (85%)]\tLoss: 1.864666\n",
            "Train Epoch: 14 [12800/13572 (94%)]\tLoss: 1.745396\n",
            "\n",
            "Validation set: Average loss: 2.9929, Accuracy: 158.0/500 (32%)\n",
            "\n",
            "Train Epoch: 15 [0/13572 (0%)]\tLoss: 1.577149\n",
            "Train Epoch: 15 [1280/13572 (9%)]\tLoss: 1.880983\n",
            "Train Epoch: 15 [2560/13572 (19%)]\tLoss: 1.540735\n",
            "Train Epoch: 15 [3840/13572 (28%)]\tLoss: 1.666955\n",
            "Train Epoch: 15 [5120/13572 (38%)]\tLoss: 1.392026\n",
            "Train Epoch: 15 [6400/13572 (47%)]\tLoss: 1.302366\n",
            "Train Epoch: 15 [7680/13572 (57%)]\tLoss: 1.675394\n",
            "Train Epoch: 15 [8960/13572 (66%)]\tLoss: 1.395448\n",
            "Train Epoch: 15 [10240/13572 (75%)]\tLoss: 1.593182\n",
            "Train Epoch: 15 [11520/13572 (85%)]\tLoss: 1.845801\n",
            "Train Epoch: 15 [12800/13572 (94%)]\tLoss: 1.714074\n",
            "\n",
            "Validation set: Average loss: 2.5064, Accuracy: 195.0/500 (39%)\n",
            "\n",
            "Train Epoch: 16 [0/13572 (0%)]\tLoss: 1.722055\n",
            "Train Epoch: 16 [1280/13572 (9%)]\tLoss: 1.731948\n",
            "Train Epoch: 16 [2560/13572 (19%)]\tLoss: 1.572444\n",
            "Train Epoch: 16 [3840/13572 (28%)]\tLoss: 1.493994\n",
            "Train Epoch: 16 [5120/13572 (38%)]\tLoss: 1.431698\n",
            "Train Epoch: 16 [6400/13572 (47%)]\tLoss: 1.710288\n",
            "Train Epoch: 16 [7680/13572 (57%)]\tLoss: 1.396229\n",
            "Train Epoch: 16 [8960/13572 (66%)]\tLoss: 1.448515\n",
            "Train Epoch: 16 [10240/13572 (75%)]\tLoss: 1.577614\n",
            "Train Epoch: 16 [11520/13572 (85%)]\tLoss: 1.537099\n",
            "Train Epoch: 16 [12800/13572 (94%)]\tLoss: 1.457746\n",
            "\n",
            "Validation set: Average loss: 2.4444, Accuracy: 199.0/500 (40%)\n",
            "\n",
            "Train Epoch: 17 [0/13572 (0%)]\tLoss: 1.477061\n",
            "Train Epoch: 17 [1280/13572 (9%)]\tLoss: 1.547742\n",
            "Train Epoch: 17 [2560/13572 (19%)]\tLoss: 1.714192\n",
            "Train Epoch: 17 [3840/13572 (28%)]\tLoss: 1.565311\n",
            "Train Epoch: 17 [5120/13572 (38%)]\tLoss: 1.469103\n",
            "Train Epoch: 17 [6400/13572 (47%)]\tLoss: 1.420519\n",
            "Train Epoch: 17 [7680/13572 (57%)]\tLoss: 1.725750\n",
            "Train Epoch: 17 [8960/13572 (66%)]\tLoss: 1.582103\n",
            "Train Epoch: 17 [10240/13572 (75%)]\tLoss: 1.502427\n",
            "Train Epoch: 17 [11520/13572 (85%)]\tLoss: 1.392861\n",
            "Train Epoch: 17 [12800/13572 (94%)]\tLoss: 1.507831\n",
            "\n",
            "Validation set: Average loss: 3.0588, Accuracy: 175.0/500 (35%)\n",
            "\n",
            "Train Epoch: 18 [0/13572 (0%)]\tLoss: 1.503532\n",
            "Train Epoch: 18 [1280/13572 (9%)]\tLoss: 1.799658\n",
            "Train Epoch: 18 [2560/13572 (19%)]\tLoss: 1.677143\n",
            "Train Epoch: 18 [3840/13572 (28%)]\tLoss: 1.530208\n",
            "Train Epoch: 18 [5120/13572 (38%)]\tLoss: 1.386722\n",
            "Train Epoch: 18 [6400/13572 (47%)]\tLoss: 1.352959\n",
            "Train Epoch: 18 [7680/13572 (57%)]\tLoss: 1.536369\n",
            "Train Epoch: 18 [8960/13572 (66%)]\tLoss: 1.254858\n",
            "Train Epoch: 18 [10240/13572 (75%)]\tLoss: 1.100380\n",
            "Train Epoch: 18 [11520/13572 (85%)]\tLoss: 1.212854\n",
            "Train Epoch: 18 [12800/13572 (94%)]\tLoss: 1.493555\n",
            "\n",
            "Validation set: Average loss: 2.5491, Accuracy: 193.0/500 (39%)\n",
            "\n",
            "Train Epoch: 19 [0/13572 (0%)]\tLoss: 1.131444\n",
            "Train Epoch: 19 [1280/13572 (9%)]\tLoss: 1.510754\n",
            "Train Epoch: 19 [2560/13572 (19%)]\tLoss: 1.279527\n",
            "Train Epoch: 19 [3840/13572 (28%)]\tLoss: 1.116160\n",
            "Train Epoch: 19 [5120/13572 (38%)]\tLoss: 1.565639\n",
            "Train Epoch: 19 [6400/13572 (47%)]\tLoss: 1.174495\n",
            "Train Epoch: 19 [7680/13572 (57%)]\tLoss: 1.150117\n",
            "Train Epoch: 19 [8960/13572 (66%)]\tLoss: 1.369062\n",
            "Train Epoch: 19 [10240/13572 (75%)]\tLoss: 1.427335\n",
            "Train Epoch: 19 [11520/13572 (85%)]\tLoss: 1.490809\n",
            "Train Epoch: 19 [12800/13572 (94%)]\tLoss: 1.427315\n",
            "\n",
            "Validation set: Average loss: 2.3359, Accuracy: 214.0/500 (43%)\n",
            "\n",
            "Train Epoch: 20 [0/13572 (0%)]\tLoss: 1.190210\n",
            "Train Epoch: 20 [1280/13572 (9%)]\tLoss: 1.278867\n",
            "Train Epoch: 20 [2560/13572 (19%)]\tLoss: 1.505693\n",
            "Train Epoch: 20 [3840/13572 (28%)]\tLoss: 1.497262\n",
            "Train Epoch: 20 [5120/13572 (38%)]\tLoss: 1.292590\n",
            "Train Epoch: 20 [6400/13572 (47%)]\tLoss: 1.179638\n",
            "Train Epoch: 20 [7680/13572 (57%)]\tLoss: 1.106461\n",
            "Train Epoch: 20 [8960/13572 (66%)]\tLoss: 1.045645\n",
            "Train Epoch: 20 [10240/13572 (75%)]\tLoss: 0.969394\n",
            "Train Epoch: 20 [11520/13572 (85%)]\tLoss: 1.353024\n",
            "Train Epoch: 20 [12800/13572 (94%)]\tLoss: 1.138339\n",
            "\n",
            "Validation set: Average loss: 2.5855, Accuracy: 207.0/500 (41%)\n",
            "\n",
            "Train Epoch: 21 [0/13572 (0%)]\tLoss: 0.983798\n",
            "Train Epoch: 21 [1280/13572 (9%)]\tLoss: 1.196306\n",
            "Train Epoch: 21 [2560/13572 (19%)]\tLoss: 1.056207\n",
            "Train Epoch: 21 [3840/13572 (28%)]\tLoss: 0.793802\n",
            "Train Epoch: 21 [5120/13572 (38%)]\tLoss: 1.334809\n",
            "Train Epoch: 21 [6400/13572 (47%)]\tLoss: 1.222303\n",
            "Train Epoch: 21 [7680/13572 (57%)]\tLoss: 0.974650\n",
            "Train Epoch: 21 [8960/13572 (66%)]\tLoss: 1.143895\n",
            "Train Epoch: 21 [10240/13572 (75%)]\tLoss: 1.237939\n",
            "Train Epoch: 21 [11520/13572 (85%)]\tLoss: 1.449051\n",
            "Train Epoch: 21 [12800/13572 (94%)]\tLoss: 0.989670\n",
            "\n",
            "Validation set: Average loss: 3.3884, Accuracy: 168.0/500 (34%)\n",
            "\n",
            "Train Epoch: 22 [0/13572 (0%)]\tLoss: 0.884347\n",
            "Train Epoch: 22 [1280/13572 (9%)]\tLoss: 1.209930\n",
            "Train Epoch: 22 [2560/13572 (19%)]\tLoss: 1.247179\n",
            "Train Epoch: 22 [3840/13572 (28%)]\tLoss: 1.103279\n",
            "Train Epoch: 22 [5120/13572 (38%)]\tLoss: 1.120900\n",
            "Train Epoch: 22 [6400/13572 (47%)]\tLoss: 1.208048\n",
            "Train Epoch: 22 [7680/13572 (57%)]\tLoss: 0.923719\n",
            "Train Epoch: 22 [8960/13572 (66%)]\tLoss: 0.890985\n",
            "Train Epoch: 22 [10240/13572 (75%)]\tLoss: 1.065393\n",
            "Train Epoch: 22 [11520/13572 (85%)]\tLoss: 0.999183\n",
            "Train Epoch: 22 [12800/13572 (94%)]\tLoss: 0.893881\n",
            "\n",
            "Validation set: Average loss: 3.0692, Accuracy: 183.0/500 (37%)\n",
            "\n",
            "Train Epoch: 23 [0/13572 (0%)]\tLoss: 1.088928\n",
            "Train Epoch: 23 [1280/13572 (9%)]\tLoss: 1.606475\n",
            "Train Epoch: 23 [2560/13572 (19%)]\tLoss: 1.296540\n",
            "Train Epoch: 23 [3840/13572 (28%)]\tLoss: 1.266284\n",
            "Train Epoch: 23 [5120/13572 (38%)]\tLoss: 0.879832\n",
            "Train Epoch: 23 [6400/13572 (47%)]\tLoss: 1.112666\n",
            "Train Epoch: 23 [7680/13572 (57%)]\tLoss: 0.916832\n",
            "Train Epoch: 23 [8960/13572 (66%)]\tLoss: 0.914082\n",
            "Train Epoch: 23 [10240/13572 (75%)]\tLoss: 0.994950\n",
            "Train Epoch: 23 [11520/13572 (85%)]\tLoss: 0.854348\n",
            "Train Epoch: 23 [12800/13572 (94%)]\tLoss: 1.034236\n",
            "\n",
            "Validation set: Average loss: 2.6709, Accuracy: 200.0/500 (40%)\n",
            "\n",
            "Train Epoch: 24 [0/13572 (0%)]\tLoss: 1.216392\n",
            "Train Epoch: 24 [1280/13572 (9%)]\tLoss: 1.495853\n",
            "Train Epoch: 24 [2560/13572 (19%)]\tLoss: 1.488710\n",
            "Train Epoch: 24 [3840/13572 (28%)]\tLoss: 1.123704\n",
            "Train Epoch: 24 [5120/13572 (38%)]\tLoss: 0.922186\n",
            "Train Epoch: 24 [6400/13572 (47%)]\tLoss: 1.105434\n",
            "Train Epoch: 24 [7680/13572 (57%)]\tLoss: 1.141724\n",
            "Train Epoch: 24 [8960/13572 (66%)]\tLoss: 0.927946\n",
            "Train Epoch: 24 [10240/13572 (75%)]\tLoss: 1.115046\n",
            "Train Epoch: 24 [11520/13572 (85%)]\tLoss: 0.957801\n",
            "Train Epoch: 24 [12800/13572 (94%)]\tLoss: 0.806832\n",
            "\n",
            "Validation set: Average loss: 2.5086, Accuracy: 215.0/500 (43%)\n",
            "\n",
            "Train Epoch: 25 [0/13572 (0%)]\tLoss: 0.721540\n",
            "Train Epoch: 25 [1280/13572 (9%)]\tLoss: 1.123722\n",
            "Train Epoch: 25 [2560/13572 (19%)]\tLoss: 0.768306\n",
            "Train Epoch: 25 [3840/13572 (28%)]\tLoss: 1.024004\n",
            "Train Epoch: 25 [5120/13572 (38%)]\tLoss: 1.061348\n",
            "Train Epoch: 25 [6400/13572 (47%)]\tLoss: 0.930652\n",
            "Train Epoch: 25 [7680/13572 (57%)]\tLoss: 0.709470\n",
            "Train Epoch: 25 [8960/13572 (66%)]\tLoss: 0.885445\n",
            "Train Epoch: 25 [10240/13572 (75%)]\tLoss: 1.025535\n",
            "Train Epoch: 25 [11520/13572 (85%)]\tLoss: 0.866109\n",
            "Train Epoch: 25 [12800/13572 (94%)]\tLoss: 0.932222\n",
            "\n",
            "Validation set: Average loss: 2.5078, Accuracy: 226.0/500 (45%)\n",
            "\n",
            "Train Epoch: 26 [0/13572 (0%)]\tLoss: 0.656675\n",
            "Train Epoch: 26 [1280/13572 (9%)]\tLoss: 0.620921\n",
            "Train Epoch: 26 [2560/13572 (19%)]\tLoss: 0.798353\n",
            "Train Epoch: 26 [3840/13572 (28%)]\tLoss: 0.739674\n",
            "Train Epoch: 26 [5120/13572 (38%)]\tLoss: 0.891831\n",
            "Train Epoch: 26 [6400/13572 (47%)]\tLoss: 0.841811\n",
            "Train Epoch: 26 [7680/13572 (57%)]\tLoss: 0.730453\n",
            "Train Epoch: 26 [8960/13572 (66%)]\tLoss: 0.970197\n",
            "Train Epoch: 26 [10240/13572 (75%)]\tLoss: 0.577719\n",
            "Train Epoch: 26 [11520/13572 (85%)]\tLoss: 0.902976\n",
            "Train Epoch: 26 [12800/13572 (94%)]\tLoss: 0.770017\n",
            "\n",
            "Validation set: Average loss: 2.6030, Accuracy: 211.0/500 (42%)\n",
            "\n",
            "Train Epoch: 27 [0/13572 (0%)]\tLoss: 1.025804\n",
            "Train Epoch: 27 [1280/13572 (9%)]\tLoss: 0.732945\n",
            "Train Epoch: 27 [2560/13572 (19%)]\tLoss: 0.648046\n",
            "Train Epoch: 27 [3840/13572 (28%)]\tLoss: 0.657268\n",
            "Train Epoch: 27 [5120/13572 (38%)]\tLoss: 0.746683\n",
            "Train Epoch: 27 [6400/13572 (47%)]\tLoss: 0.790119\n",
            "Train Epoch: 27 [7680/13572 (57%)]\tLoss: 0.588275\n",
            "Train Epoch: 27 [8960/13572 (66%)]\tLoss: 0.639454\n",
            "Train Epoch: 27 [10240/13572 (75%)]\tLoss: 0.692719\n",
            "Train Epoch: 27 [11520/13572 (85%)]\tLoss: 0.953842\n",
            "Train Epoch: 27 [12800/13572 (94%)]\tLoss: 0.693709\n",
            "\n",
            "Validation set: Average loss: 2.6896, Accuracy: 216.0/500 (43%)\n",
            "\n",
            "Train Epoch: 28 [0/13572 (0%)]\tLoss: 0.688211\n",
            "Train Epoch: 28 [1280/13572 (9%)]\tLoss: 0.739062\n",
            "Train Epoch: 28 [2560/13572 (19%)]\tLoss: 0.820365\n",
            "Train Epoch: 28 [3840/13572 (28%)]\tLoss: 0.846722\n",
            "Train Epoch: 28 [5120/13572 (38%)]\tLoss: 0.820794\n",
            "Train Epoch: 28 [6400/13572 (47%)]\tLoss: 0.740376\n",
            "Train Epoch: 28 [7680/13572 (57%)]\tLoss: 0.759443\n",
            "Train Epoch: 28 [8960/13572 (66%)]\tLoss: 0.600384\n",
            "Train Epoch: 28 [10240/13572 (75%)]\tLoss: 0.689196\n",
            "Train Epoch: 28 [11520/13572 (85%)]\tLoss: 0.887126\n",
            "Train Epoch: 28 [12800/13572 (94%)]\tLoss: 0.568713\n",
            "\n",
            "Validation set: Average loss: 2.8590, Accuracy: 216.0/500 (43%)\n",
            "\n",
            "Train Epoch: 29 [0/13572 (0%)]\tLoss: 0.493864\n",
            "Train Epoch: 29 [1280/13572 (9%)]\tLoss: 0.920738\n",
            "Train Epoch: 29 [2560/13572 (19%)]\tLoss: 0.655116\n",
            "Train Epoch: 29 [3840/13572 (28%)]\tLoss: 0.593992\n",
            "Train Epoch: 29 [5120/13572 (38%)]\tLoss: 0.491286\n",
            "Train Epoch: 29 [6400/13572 (47%)]\tLoss: 0.897617\n",
            "Train Epoch: 29 [7680/13572 (57%)]\tLoss: 0.723827\n",
            "Train Epoch: 29 [8960/13572 (66%)]\tLoss: 0.680665\n",
            "Train Epoch: 29 [10240/13572 (75%)]\tLoss: 0.743075\n",
            "Train Epoch: 29 [11520/13572 (85%)]\tLoss: 0.679660\n",
            "Train Epoch: 29 [12800/13572 (94%)]\tLoss: 0.596731\n",
            "\n",
            "Validation set: Average loss: 3.4425, Accuracy: 185.0/500 (37%)\n",
            "\n",
            "Train Epoch: 30 [0/13572 (0%)]\tLoss: 0.708550\n",
            "Train Epoch: 30 [1280/13572 (9%)]\tLoss: 1.122627\n",
            "Train Epoch: 30 [2560/13572 (19%)]\tLoss: 0.774807\n",
            "Train Epoch: 30 [3840/13572 (28%)]\tLoss: 0.657869\n",
            "Train Epoch: 30 [5120/13572 (38%)]\tLoss: 0.575563\n",
            "Train Epoch: 30 [6400/13572 (47%)]\tLoss: 0.645046\n",
            "Train Epoch: 30 [7680/13572 (57%)]\tLoss: 0.715502\n",
            "Train Epoch: 30 [8960/13572 (66%)]\tLoss: 0.926493\n",
            "Train Epoch: 30 [10240/13572 (75%)]\tLoss: 0.593786\n",
            "Train Epoch: 30 [11520/13572 (85%)]\tLoss: 0.739787\n",
            "Train Epoch: 30 [12800/13572 (94%)]\tLoss: 0.776967\n",
            "\n",
            "Validation set: Average loss: 2.7946, Accuracy: 213.0/500 (43%)\n",
            "\n",
            "Train Epoch: 31 [0/13572 (0%)]\tLoss: 0.430597\n",
            "Train Epoch: 31 [1280/13572 (9%)]\tLoss: 0.473161\n",
            "Train Epoch: 31 [2560/13572 (19%)]\tLoss: 0.460503\n",
            "Train Epoch: 31 [3840/13572 (28%)]\tLoss: 0.699415\n",
            "Train Epoch: 31 [5120/13572 (38%)]\tLoss: 0.673304\n",
            "Train Epoch: 31 [6400/13572 (47%)]\tLoss: 0.533309\n",
            "Train Epoch: 31 [7680/13572 (57%)]\tLoss: 0.583797\n",
            "Train Epoch: 31 [8960/13572 (66%)]\tLoss: 0.726844\n",
            "Train Epoch: 31 [10240/13572 (75%)]\tLoss: 0.742387\n",
            "Train Epoch: 31 [11520/13572 (85%)]\tLoss: 0.550323\n",
            "Train Epoch: 31 [12800/13572 (94%)]\tLoss: 0.464832\n",
            "\n",
            "Validation set: Average loss: 4.2393, Accuracy: 162.0/500 (32%)\n",
            "\n",
            "Train Epoch: 32 [0/13572 (0%)]\tLoss: 0.987411\n",
            "Train Epoch: 32 [1280/13572 (9%)]\tLoss: 1.885725\n",
            "Train Epoch: 32 [2560/13572 (19%)]\tLoss: 1.092414\n",
            "Train Epoch: 32 [3840/13572 (28%)]\tLoss: 1.032656\n",
            "Train Epoch: 32 [5120/13572 (38%)]\tLoss: 0.946391\n",
            "Train Epoch: 32 [6400/13572 (47%)]\tLoss: 0.836146\n",
            "Train Epoch: 32 [7680/13572 (57%)]\tLoss: 0.927528\n",
            "Train Epoch: 32 [8960/13572 (66%)]\tLoss: 0.724140\n",
            "Train Epoch: 32 [10240/13572 (75%)]\tLoss: 0.553117\n",
            "Train Epoch: 32 [11520/13572 (85%)]\tLoss: 0.568805\n",
            "Train Epoch: 32 [12800/13572 (94%)]\tLoss: 0.589113\n",
            "\n",
            "Validation set: Average loss: 2.8788, Accuracy: 218.0/500 (44%)\n",
            "\n",
            "Train Epoch: 33 [0/13572 (0%)]\tLoss: 0.561091\n",
            "Train Epoch: 33 [1280/13572 (9%)]\tLoss: 0.471844\n",
            "Train Epoch: 33 [2560/13572 (19%)]\tLoss: 0.455262\n",
            "Train Epoch: 33 [3840/13572 (28%)]\tLoss: 0.634387\n",
            "Train Epoch: 33 [5120/13572 (38%)]\tLoss: 0.602725\n",
            "Train Epoch: 33 [6400/13572 (47%)]\tLoss: 0.540825\n",
            "Train Epoch: 33 [7680/13572 (57%)]\tLoss: 0.409738\n",
            "Train Epoch: 33 [8960/13572 (66%)]\tLoss: 0.509844\n",
            "Train Epoch: 33 [10240/13572 (75%)]\tLoss: 0.616001\n",
            "Train Epoch: 33 [11520/13572 (85%)]\tLoss: 0.457455\n",
            "Train Epoch: 33 [12800/13572 (94%)]\tLoss: 0.590167\n",
            "\n",
            "Validation set: Average loss: 3.4755, Accuracy: 206.0/500 (41%)\n",
            "\n",
            "Train Epoch: 34 [0/13572 (0%)]\tLoss: 0.347280\n",
            "Train Epoch: 34 [1280/13572 (9%)]\tLoss: 0.659409\n",
            "Train Epoch: 34 [2560/13572 (19%)]\tLoss: 0.627142\n",
            "Train Epoch: 34 [3840/13572 (28%)]\tLoss: 0.576097\n",
            "Train Epoch: 34 [5120/13572 (38%)]\tLoss: 0.660591\n",
            "Train Epoch: 34 [6400/13572 (47%)]\tLoss: 0.534302\n",
            "Train Epoch: 34 [7680/13572 (57%)]\tLoss: 0.442155\n",
            "Train Epoch: 34 [8960/13572 (66%)]\tLoss: 0.422171\n",
            "Train Epoch: 34 [10240/13572 (75%)]\tLoss: 0.593273\n",
            "Train Epoch: 34 [11520/13572 (85%)]\tLoss: 0.462940\n",
            "Train Epoch: 34 [12800/13572 (94%)]\tLoss: 0.446251\n",
            "\n",
            "Validation set: Average loss: 3.0490, Accuracy: 197.0/500 (39%)\n",
            "\n",
            "Train Epoch: 35 [0/13572 (0%)]\tLoss: 0.768679\n",
            "Train Epoch: 35 [1280/13572 (9%)]\tLoss: 0.851833\n",
            "Train Epoch: 35 [2560/13572 (19%)]\tLoss: 0.644121\n",
            "Train Epoch: 35 [3840/13572 (28%)]\tLoss: 0.674450\n",
            "Train Epoch: 35 [5120/13572 (38%)]\tLoss: 0.573141\n",
            "Train Epoch: 35 [6400/13572 (47%)]\tLoss: 0.535489\n",
            "Train Epoch: 35 [7680/13572 (57%)]\tLoss: 0.545201\n",
            "Train Epoch: 35 [8960/13572 (66%)]\tLoss: 0.621511\n",
            "Train Epoch: 35 [10240/13572 (75%)]\tLoss: 0.759660\n",
            "Train Epoch: 35 [11520/13572 (85%)]\tLoss: 0.466239\n",
            "Train Epoch: 35 [12800/13572 (94%)]\tLoss: 0.596717\n",
            "\n",
            "Validation set: Average loss: 3.0470, Accuracy: 218.0/500 (44%)\n",
            "\n",
            "Train Epoch: 36 [0/13572 (0%)]\tLoss: 0.350707\n",
            "Train Epoch: 36 [1280/13572 (9%)]\tLoss: 0.483576\n",
            "Train Epoch: 36 [2560/13572 (19%)]\tLoss: 0.466541\n",
            "Train Epoch: 36 [3840/13572 (28%)]\tLoss: 0.590727\n",
            "Train Epoch: 36 [5120/13572 (38%)]\tLoss: 0.338091\n",
            "Train Epoch: 36 [6400/13572 (47%)]\tLoss: 0.457854\n",
            "Train Epoch: 36 [7680/13572 (57%)]\tLoss: 0.376773\n",
            "Train Epoch: 36 [8960/13572 (66%)]\tLoss: 0.564983\n",
            "Train Epoch: 36 [10240/13572 (75%)]\tLoss: 0.479772\n",
            "Train Epoch: 36 [11520/13572 (85%)]\tLoss: 0.393237\n",
            "Train Epoch: 36 [12800/13572 (94%)]\tLoss: 0.429826\n",
            "\n",
            "Validation set: Average loss: 2.9610, Accuracy: 214.0/500 (43%)\n",
            "\n",
            "Train Epoch: 37 [0/13572 (0%)]\tLoss: 0.347596\n",
            "Train Epoch: 37 [1280/13572 (9%)]\tLoss: 0.538992\n",
            "Train Epoch: 37 [2560/13572 (19%)]\tLoss: 0.470858\n",
            "Train Epoch: 37 [3840/13572 (28%)]\tLoss: 0.570335\n",
            "Train Epoch: 37 [5120/13572 (38%)]\tLoss: 0.376399\n",
            "Train Epoch: 37 [6400/13572 (47%)]\tLoss: 0.463519\n",
            "Train Epoch: 37 [7680/13572 (57%)]\tLoss: 0.594737\n",
            "Train Epoch: 37 [8960/13572 (66%)]\tLoss: 0.384892\n",
            "Train Epoch: 37 [10240/13572 (75%)]\tLoss: 0.489719\n",
            "Train Epoch: 37 [11520/13572 (85%)]\tLoss: 0.386990\n",
            "Train Epoch: 37 [12800/13572 (94%)]\tLoss: 0.423771\n",
            "\n",
            "Validation set: Average loss: 2.9553, Accuracy: 227.0/500 (45%)\n",
            "\n",
            "Train Epoch: 38 [0/13572 (0%)]\tLoss: 0.322040\n",
            "Train Epoch: 38 [1280/13572 (9%)]\tLoss: 0.722731\n",
            "Train Epoch: 38 [2560/13572 (19%)]\tLoss: 0.506557\n",
            "Train Epoch: 38 [3840/13572 (28%)]\tLoss: 0.351052\n",
            "Train Epoch: 38 [5120/13572 (38%)]\tLoss: 0.271030\n",
            "Train Epoch: 38 [6400/13572 (47%)]\tLoss: 0.313537\n",
            "Train Epoch: 38 [7680/13572 (57%)]\tLoss: 0.365525\n",
            "Train Epoch: 38 [8960/13572 (66%)]\tLoss: 0.518839\n",
            "Train Epoch: 38 [10240/13572 (75%)]\tLoss: 0.374247\n",
            "Train Epoch: 38 [11520/13572 (85%)]\tLoss: 0.487078\n",
            "Train Epoch: 38 [12800/13572 (94%)]\tLoss: 0.472146\n",
            "\n",
            "Validation set: Average loss: 3.3087, Accuracy: 207.0/500 (41%)\n",
            "\n",
            "Train Epoch: 39 [0/13572 (0%)]\tLoss: 0.415477\n",
            "Train Epoch: 39 [1280/13572 (9%)]\tLoss: 0.358371\n",
            "Train Epoch: 39 [2560/13572 (19%)]\tLoss: 0.359021\n",
            "Train Epoch: 39 [3840/13572 (28%)]\tLoss: 0.419512\n",
            "Train Epoch: 39 [5120/13572 (38%)]\tLoss: 0.372467\n",
            "Train Epoch: 39 [6400/13572 (47%)]\tLoss: 0.286338\n",
            "Train Epoch: 39 [7680/13572 (57%)]\tLoss: 0.237522\n",
            "Train Epoch: 39 [8960/13572 (66%)]\tLoss: 0.394772\n",
            "Train Epoch: 39 [10240/13572 (75%)]\tLoss: 0.317278\n",
            "Train Epoch: 39 [11520/13572 (85%)]\tLoss: 0.307443\n",
            "Train Epoch: 39 [12800/13572 (94%)]\tLoss: 0.468414\n",
            "\n",
            "Validation set: Average loss: 3.1449, Accuracy: 227.0/500 (45%)\n",
            "\n",
            "Train Epoch: 40 [0/13572 (0%)]\tLoss: 0.429252\n",
            "Train Epoch: 40 [1280/13572 (9%)]\tLoss: 0.561764\n",
            "Train Epoch: 40 [2560/13572 (19%)]\tLoss: 0.590192\n",
            "Train Epoch: 40 [3840/13572 (28%)]\tLoss: 0.311023\n",
            "Train Epoch: 40 [5120/13572 (38%)]\tLoss: 0.311390\n",
            "Train Epoch: 40 [6400/13572 (47%)]\tLoss: 0.359767\n",
            "Train Epoch: 40 [7680/13572 (57%)]\tLoss: 0.309786\n",
            "Train Epoch: 40 [8960/13572 (66%)]\tLoss: 0.588765\n",
            "Train Epoch: 40 [10240/13572 (75%)]\tLoss: 0.305814\n",
            "Train Epoch: 40 [11520/13572 (85%)]\tLoss: 0.448563\n",
            "Train Epoch: 40 [12800/13572 (94%)]\tLoss: 0.547954\n",
            "\n",
            "Validation set: Average loss: 2.9716, Accuracy: 243.0/500 (49%)\n",
            "\n",
            "Train Epoch: 41 [0/13572 (0%)]\tLoss: 0.254700\n",
            "Train Epoch: 41 [1280/13572 (9%)]\tLoss: 0.367890\n",
            "Train Epoch: 41 [2560/13572 (19%)]\tLoss: 0.311881\n",
            "Train Epoch: 41 [3840/13572 (28%)]\tLoss: 0.259877\n",
            "Train Epoch: 41 [5120/13572 (38%)]\tLoss: 0.335686\n",
            "Train Epoch: 41 [6400/13572 (47%)]\tLoss: 0.290069\n",
            "Train Epoch: 41 [7680/13572 (57%)]\tLoss: 0.301443\n",
            "Train Epoch: 41 [8960/13572 (66%)]\tLoss: 0.259332\n",
            "Train Epoch: 41 [10240/13572 (75%)]\tLoss: 0.295865\n",
            "Train Epoch: 41 [11520/13572 (85%)]\tLoss: 0.339396\n",
            "Train Epoch: 41 [12800/13572 (94%)]\tLoss: 0.368831\n",
            "\n",
            "Validation set: Average loss: 3.5569, Accuracy: 210.0/500 (42%)\n",
            "\n",
            "Train Epoch: 42 [0/13572 (0%)]\tLoss: 0.357007\n",
            "Train Epoch: 42 [1280/13572 (9%)]\tLoss: 0.719902\n",
            "Train Epoch: 42 [2560/13572 (19%)]\tLoss: 0.477008\n",
            "Train Epoch: 42 [3840/13572 (28%)]\tLoss: 0.531869\n",
            "Train Epoch: 42 [5120/13572 (38%)]\tLoss: 0.485865\n",
            "Train Epoch: 42 [6400/13572 (47%)]\tLoss: 0.324681\n",
            "Train Epoch: 42 [7680/13572 (57%)]\tLoss: 0.202549\n",
            "Train Epoch: 42 [8960/13572 (66%)]\tLoss: 0.330402\n",
            "Train Epoch: 42 [10240/13572 (75%)]\tLoss: 0.363807\n",
            "Train Epoch: 42 [11520/13572 (85%)]\tLoss: 0.405580\n",
            "Train Epoch: 42 [12800/13572 (94%)]\tLoss: 0.343766\n",
            "\n",
            "Validation set: Average loss: 3.2511, Accuracy: 218.0/500 (44%)\n",
            "\n",
            "Train Epoch: 43 [0/13572 (0%)]\tLoss: 0.266494\n",
            "Train Epoch: 43 [1280/13572 (9%)]\tLoss: 0.270464\n",
            "Train Epoch: 43 [2560/13572 (19%)]\tLoss: 0.208701\n",
            "Train Epoch: 43 [3840/13572 (28%)]\tLoss: 0.203318\n",
            "Train Epoch: 43 [5120/13572 (38%)]\tLoss: 0.242460\n",
            "Train Epoch: 43 [6400/13572 (47%)]\tLoss: 0.367501\n",
            "Train Epoch: 43 [7680/13572 (57%)]\tLoss: 0.200438\n",
            "Train Epoch: 43 [8960/13572 (66%)]\tLoss: 0.222929\n",
            "Train Epoch: 43 [10240/13572 (75%)]\tLoss: 0.261829\n",
            "Train Epoch: 43 [11520/13572 (85%)]\tLoss: 0.188179\n",
            "Train Epoch: 43 [12800/13572 (94%)]\tLoss: 0.335554\n",
            "\n",
            "Validation set: Average loss: 3.4709, Accuracy: 211.0/500 (42%)\n",
            "\n",
            "Train Epoch: 44 [0/13572 (0%)]\tLoss: 0.300850\n",
            "Train Epoch: 44 [1280/13572 (9%)]\tLoss: 0.530798\n",
            "Train Epoch: 44 [2560/13572 (19%)]\tLoss: 0.454463\n",
            "Train Epoch: 44 [3840/13572 (28%)]\tLoss: 0.491030\n",
            "Train Epoch: 44 [5120/13572 (38%)]\tLoss: 0.332745\n",
            "Train Epoch: 44 [6400/13572 (47%)]\tLoss: 0.304262\n",
            "Train Epoch: 44 [7680/13572 (57%)]\tLoss: 0.271001\n",
            "Train Epoch: 44 [8960/13572 (66%)]\tLoss: 0.240549\n",
            "Train Epoch: 44 [10240/13572 (75%)]\tLoss: 0.228402\n",
            "Train Epoch: 44 [11520/13572 (85%)]\tLoss: 0.341350\n",
            "Train Epoch: 44 [12800/13572 (94%)]\tLoss: 0.262173\n",
            "\n",
            "Validation set: Average loss: 3.8225, Accuracy: 213.0/500 (43%)\n",
            "\n",
            "Train Epoch: 45 [0/13572 (0%)]\tLoss: 0.344967\n",
            "Train Epoch: 45 [1280/13572 (9%)]\tLoss: 0.621111\n",
            "Train Epoch: 45 [2560/13572 (19%)]\tLoss: 0.435409\n",
            "Train Epoch: 45 [3840/13572 (28%)]\tLoss: 0.521183\n",
            "Train Epoch: 45 [5120/13572 (38%)]\tLoss: 0.316542\n",
            "Train Epoch: 45 [6400/13572 (47%)]\tLoss: 0.244782\n",
            "Train Epoch: 45 [7680/13572 (57%)]\tLoss: 0.340403\n",
            "Train Epoch: 45 [8960/13572 (66%)]\tLoss: 0.551048\n",
            "Train Epoch: 45 [10240/13572 (75%)]\tLoss: 0.301717\n",
            "Train Epoch: 45 [11520/13572 (85%)]\tLoss: 0.208124\n",
            "Train Epoch: 45 [12800/13572 (94%)]\tLoss: 0.280405\n",
            "\n",
            "Validation set: Average loss: 3.3314, Accuracy: 211.0/500 (42%)\n",
            "\n",
            "Train Epoch: 46 [0/13572 (0%)]\tLoss: 0.337083\n",
            "Train Epoch: 46 [1280/13572 (9%)]\tLoss: 1.184189\n",
            "Train Epoch: 46 [2560/13572 (19%)]\tLoss: 0.480364\n",
            "Train Epoch: 46 [3840/13572 (28%)]\tLoss: 0.438356\n",
            "Train Epoch: 46 [5120/13572 (38%)]\tLoss: 0.449964\n",
            "Train Epoch: 46 [6400/13572 (47%)]\tLoss: 0.433591\n",
            "Train Epoch: 46 [7680/13572 (57%)]\tLoss: 0.336983\n",
            "Train Epoch: 46 [8960/13572 (66%)]\tLoss: 0.379941\n",
            "Train Epoch: 46 [10240/13572 (75%)]\tLoss: 0.507556\n",
            "Train Epoch: 46 [11520/13572 (85%)]\tLoss: 0.417435\n",
            "Train Epoch: 46 [12800/13572 (94%)]\tLoss: 0.340200\n",
            "\n",
            "Validation set: Average loss: 3.4264, Accuracy: 218.0/500 (44%)\n",
            "\n",
            "Train Epoch: 47 [0/13572 (0%)]\tLoss: 0.179170\n",
            "Train Epoch: 47 [1280/13572 (9%)]\tLoss: 0.351010\n",
            "Train Epoch: 47 [2560/13572 (19%)]\tLoss: 0.251612\n",
            "Train Epoch: 47 [3840/13572 (28%)]\tLoss: 0.247434\n",
            "Train Epoch: 47 [5120/13572 (38%)]\tLoss: 0.351978\n",
            "Train Epoch: 47 [6400/13572 (47%)]\tLoss: 0.342041\n",
            "Train Epoch: 47 [7680/13572 (57%)]\tLoss: 0.465217\n",
            "Train Epoch: 47 [8960/13572 (66%)]\tLoss: 0.282313\n",
            "Train Epoch: 47 [10240/13572 (75%)]\tLoss: 0.289338\n",
            "Train Epoch: 47 [11520/13572 (85%)]\tLoss: 0.314585\n",
            "Train Epoch: 47 [12800/13572 (94%)]\tLoss: 0.233051\n",
            "\n",
            "Validation set: Average loss: 3.4148, Accuracy: 233.0/500 (47%)\n",
            "\n",
            "Train Epoch: 48 [0/13572 (0%)]\tLoss: 0.256793\n",
            "Train Epoch: 48 [1280/13572 (9%)]\tLoss: 0.291534\n",
            "Train Epoch: 48 [2560/13572 (19%)]\tLoss: 0.535830\n",
            "Train Epoch: 48 [3840/13572 (28%)]\tLoss: 0.247285\n",
            "Train Epoch: 48 [5120/13572 (38%)]\tLoss: 0.261851\n",
            "Train Epoch: 48 [6400/13572 (47%)]\tLoss: 0.227704\n",
            "Train Epoch: 48 [7680/13572 (57%)]\tLoss: 0.215488\n",
            "Train Epoch: 48 [8960/13572 (66%)]\tLoss: 0.249429\n",
            "Train Epoch: 48 [10240/13572 (75%)]\tLoss: 0.324950\n",
            "Train Epoch: 48 [11520/13572 (85%)]\tLoss: 0.192215\n",
            "Train Epoch: 48 [12800/13572 (94%)]\tLoss: 0.219088\n",
            "\n",
            "Validation set: Average loss: 3.3100, Accuracy: 221.0/500 (44%)\n",
            "\n",
            "Train Epoch: 49 [0/13572 (0%)]\tLoss: 0.104079\n",
            "Train Epoch: 49 [1280/13572 (9%)]\tLoss: 0.161259\n",
            "Train Epoch: 49 [2560/13572 (19%)]\tLoss: 0.101672\n",
            "Train Epoch: 49 [3840/13572 (28%)]\tLoss: 0.242996\n",
            "Train Epoch: 49 [5120/13572 (38%)]\tLoss: 0.193820\n",
            "Train Epoch: 49 [6400/13572 (47%)]\tLoss: 0.201593\n",
            "Train Epoch: 49 [7680/13572 (57%)]\tLoss: 0.214567\n",
            "Train Epoch: 49 [8960/13572 (66%)]\tLoss: 0.207641\n",
            "Train Epoch: 49 [10240/13572 (75%)]\tLoss: 0.208449\n",
            "Train Epoch: 49 [11520/13572 (85%)]\tLoss: 0.189584\n",
            "Train Epoch: 49 [12800/13572 (94%)]\tLoss: 0.174307\n",
            "\n",
            "Validation set: Average loss: 3.3188, Accuracy: 228.0/500 (46%)\n",
            "\n",
            "Train Epoch: 50 [0/13572 (0%)]\tLoss: 0.137860\n",
            "Train Epoch: 50 [1280/13572 (9%)]\tLoss: 0.263377\n",
            "Train Epoch: 50 [2560/13572 (19%)]\tLoss: 0.153564\n",
            "Train Epoch: 50 [3840/13572 (28%)]\tLoss: 0.247153\n",
            "Train Epoch: 50 [5120/13572 (38%)]\tLoss: 0.264566\n",
            "Train Epoch: 50 [6400/13572 (47%)]\tLoss: 0.286219\n",
            "Train Epoch: 50 [7680/13572 (57%)]\tLoss: 0.200306\n",
            "Train Epoch: 50 [8960/13572 (66%)]\tLoss: 0.279453\n",
            "Train Epoch: 50 [10240/13572 (75%)]\tLoss: 0.176038\n",
            "Train Epoch: 50 [11520/13572 (85%)]\tLoss: 0.167832\n",
            "Train Epoch: 50 [12800/13572 (94%)]\tLoss: 0.199386\n",
            "\n",
            "Validation set: Average loss: 3.6368, Accuracy: 208.0/500 (42%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    ### PLEASE WRITE YOUR CODE BELOW.\n",
        "    \n",
        "    # Train your model with train dataloader\n",
        "\n",
        "    train_loss = train(model, optimizer, criterion, train_loader, epoch)\n",
        "\n",
        "    # Validate your model with validation dataloader\n",
        "\n",
        "    validation_accuracy = validate(model, criterion, valid_loader)\n",
        "\n",
        "    ### END OF THE CODE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "m-h4GbViAtXn"
      },
      "outputs": [],
      "source": [
        "# Test your model with test dataloader\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeH2Q4l3BTzt",
        "outputId": "56c76332-641a-4c10-a9ef-673ce148de68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "torch.Size([1, 100])\n",
            "\n",
            " Test set:  Accuracy: 218.0/500 (44%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### PLEASE EXECUTE THE FOLLOWING CELL BEFORE SUBMITTING YOUR CODE\n",
        "\n",
        "### DO NOT MODIFY THIS CELL\n",
        "print(train_dataset[0][0].size())\n",
        "print(model(torch.rand(1, 3, 224, 224, device='cuda')).size())\n",
        "test(model, test_loader)\n",
        "### DO NOT MODIFY THIS CELL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YB4vSntnJ2AN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}