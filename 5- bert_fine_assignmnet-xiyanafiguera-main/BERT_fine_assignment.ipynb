{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UNIST-LIM-Lab-course/bert_fine_assignmnet-xiyanafiguera/blob/main/BERT_fine_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT Assignment \n",
        "\n",
        "The task objective is to code sentiment analysis by BERT \n",
        "\n",
        "* An assignment part is denoted by (Assingment) \n",
        "\n",
        "* Grading criteria: Points are given if all your code in this notebook is runnable and the final acc is upper than 0.5\n",
        "\n",
        "* Points are not given if the testing cell at the end of the notebook is modified or extra cells (including text) are added after the last cell. Do not change **epochs** for testing efficiently.\n",
        "\n",
        "* Testing your model with the testing cell is recommended. \n",
        "\n",
        "* Please do not re-use the code from the example code. You have to write the code yourself.\n"
      ],
      "metadata": {
        "id": "uX5PHSvCPZ5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignmnet List \n",
        "* (Assignment) 1.2 Upload tokenizer \n",
        "* (Assignment) 1.3 Make your Dataset by BertDataset function \n",
        "* (Assignment) 2.1 Make BERT Model by pretrained_model\n",
        "* (Assignment) 3.1 Freeze parameters \n",
        "* (Assignment) 3.2 Make finetune function "
      ],
      "metadata": {
        "id": "dYpHMiEbPpjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Preparing Data\n",
        "\n"
      ],
      "metadata": {
        "id": "G5lHCy6JPf4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5N5xQCLLu44",
        "outputId": "0567e119-84d9-4e3c-92eb-2af19f77ad71"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9AUSnpT6LRxI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Make BertDataset"
      ],
      "metadata": {
        "id": "WC4hTmrDPkF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class BertDataset(Dataset):\n",
        "    def __init__(self, tokenizer,max_length):\n",
        "        super(BertDataset, self).__init__()\n",
        "        self.train_csv=pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
        "        self.tokenizer=tokenizer\n",
        "        self.target=self.train_csv.iloc[:,1]\n",
        "        self.max_length=max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.train_csv)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text1 = self.train_csv.iloc[index,0]\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text1 ,\n",
        "            None,\n",
        "            pad_to_max_length=True,\n",
        "            add_special_tokens=True,\n",
        "            return_attention_mask=True,\n",
        "            max_length=self.max_length,\n",
        "        )\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'target': torch.tensor(self.train_csv.iloc[index, 1], dtype=torch.long)\n",
        "            }\n"
      ],
      "metadata": {
        "id": "PLoqJHreLYhU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Assignment) 1.2 Upload tokenizer \n",
        "* Fill out `tokenizer` by using BertTokenizer of \"prajjwal1/bert-tiny\" #(TODO:Assignment).\n"
      ],
      "metadata": {
        "id": "RX9shmrkMc0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"prajjwal1/bert-tiny\") #(TODO:Assignment)"
      ],
      "metadata": {
        "id": "oi-mt-HmQe9E"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Assignment) 1.3 Make your Dataset by `BertDataset`\n",
        "* Fill out `dataset` by using BertDataset` \n",
        "* Fill out `dataloader` by using `DataLoader` of torch.utils.data\n",
        "* Set max_length=100 \n",
        "* Set batch_size=32 "
      ],
      "metadata": {
        "id": "hDZu0W3WQDPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= BertDataset(tokenizer, max_length=100) #(TODO:Assignment)\n",
        "dataloader= DataLoader(dataset=dataset,batch_size=32) #(TODO:Assignment)"
      ],
      "metadata": {
        "id": "rDiq1rwVQDu3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Construction your Model "
      ],
      "metadata": {
        "id": "BviYLIlYQuZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Assignment) 2.1 Make BERT Model by pretrained_model \n",
        "* Use the pretrained_model `prajjwal1/bert-tiny`\n",
        "* Simplest example code is below. But you can design BERT Model appropriately.\n",
        "* Do not stack more than three layers. The grading time should not exceed 3 minutes."
      ],
      "metadata": {
        "id": "FeoopBVrQw1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example code\n",
        "import torch.nn as nn\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.bert_model = transformers.BertModel.from_pretrained(\"prajjwal1/bert-tiny\")\n",
        "        self.out = nn.Linear(128, 1)\n",
        "        \n",
        "    def forward(self,ids,mask,token_type_ids):\n",
        "        _,o2= self.bert_model(ids,attention_mask=mask,token_type_ids=token_type_ids, return_dict=False)\n",
        "        out= self.out(o2)\n",
        "        return out\n",
        "    \n",
        "model=BERT()"
      ],
      "metadata": {
        "id": "kUULLUkYdmq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72af2641-856a-4192-b640-631245479c9f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.bert_model = transformers.BertModel.from_pretrained(\"prajjwal1/bert-tiny\")\n",
        "        #(TODO:Assignment) 1) Define your BERT Model\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.out1 = nn.Linear(128, 64) \n",
        "        self.out2 = nn.Linear(64,1)\n",
        "\n",
        "    def forward(self,ids,mask,token_type_ids):\n",
        "        _,o2= self.bert_model(ids,attention_mask=mask,token_type_ids=token_type_ids, return_dict=False)\n",
        "        #(TODO:Assignment) 2) Forward your BERT Model \n",
        "        o2 = self.dropout(o2)\n",
        "        o2= self.out1(o2)\n",
        "        o2 = self.dropout(o2)\n",
        "        out = self.out2(o2)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "model=BERT()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgUzQtpMLcig",
        "outputId": "4d1be8d7-181e-428a-ead4-85f49b38e8ae"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train your Moel "
      ],
      "metadata": {
        "id": "mYOC9WXVRJxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer= optim.Adam(model.parameters(),lr= 0.0001)"
      ],
      "metadata": {
        "id": "qBayfEg9RIsp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Assignment) 3.1 Freeze parameters \n",
        "* Fill out `#(TODO:Assignment)` to freeze parameters of BERT. \n",
        "* We should update prameters of non-BERT"
      ],
      "metadata": {
        "id": "iZN9sNwSROF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.bert_model.parameters():\n",
        "  #(TODO:Assignment) 1) Set requires_grad to be False\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "_VpmE2CxLcj9"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMGh7kTLMu0S",
        "outputId": "2830b478-cdc4-45d9-c40b-4c66f4ba663c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 8,321 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Assignment) 3.2 Make finetune function \n",
        "* Fill out `#(TODO:Assignment)` to make `def fineture`\n",
        "\n",
        "1) Define loop by dataloader \n",
        "\n",
        "2) Set the grad of optimzer to be zero\n",
        "\n",
        "3) Calculate the loss_fn(output, label) and the backward of the loss_fn\n",
        "\n",
        "4) Estimate the everage accuracy of the model for each epoch \n",
        "\n",
        "5) Estimate the total everage accuracy of the model"
      ],
      "metadata": {
        "id": "DZIEkWFoR7f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune(epochs,dataloader,model,loss_fn,optimizer):\n",
        "    model.train()\n",
        "    acc = 0  \n",
        "    N = 0\n",
        "    for  epoch in range(epochs):\n",
        "        \n",
        "        #(TODO:Assignment) 1) Define loop by dataloader \n",
        "        acc_per_epoch = 0\n",
        "        loop=tqdm(enumerate(dataloader),leave=False,total=len(dataloader))\n",
        "        for batch, dl in loop:\n",
        "          ids=dl['ids']\n",
        "          token_type_ids=dl['token_type_ids']\n",
        "          mask= dl['mask']\n",
        "          label=dl['target']\n",
        "          label = label.unsqueeze(1)\n",
        "\n",
        "          #(TODO:Assignment) 2) Set the grad of optimzer to be zero\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          output=model(\n",
        "                ids=ids,\n",
        "                mask=mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "          label = label.type_as(output)\n",
        "          \n",
        "          #(TODO:Assignment) 3) Calculate the loss_fn(output, label) and the backward of the loss_fn\n",
        "          loss=loss_fn(output,label)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          #(TODO:Assignment) 4) Estimate the average accuracy of the model for each epoch \n",
        "          prediction = np.where(output >= 0, 1, 0)\n",
        "\n",
        "          num_ct = sum(1 for p, q in zip(prediction, label) if p[0] == q[0])\n",
        "          num_ss = output.shape[0]\n",
        "          \n",
        "          acc_per_epoch += float(num_ct)/float(num_ss)\n",
        "\n",
        "          \n",
        "        \n",
        "        acc_per_epoch = acc_per_epoch/len(loop)\n",
        "        acc += acc_per_epoch \n",
        "        N += 1\n",
        "        print(f'accuracy for epoch {epoch+1} is {acc_per_epoch*100:.2f}%')\n",
        "    \n",
        "    #(TODO:Assignment) 5) Estimate the total average accuracy of the model\n",
        "    \n",
        "    acc = float(acc)/float(N)\n",
        "    return model, acc"
      ],
      "metadata": {
        "id": "4KtINEYULebe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DO NOT CHANGE THE CODE AFTER (Assignment) 3.2 Make finetune function "
      ],
      "metadata": {
        "id": "scXvZnkNfmKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Train! "
      ],
      "metadata": {
        "id": "nDhaWtP7SBW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "model, acc =finetune(epochs, dataloader, model, loss_fn, optimizer)\n"
      ],
      "metadata": {
        "id": "1LFO7MUTLhOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "006eb69a-89da-4d7e-e363-306a633fbd2f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/217 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy for epoch 1 is 52.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy for epoch 2 is 56.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy for epoch 3 is 57.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy for epoch 4 is 58.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy for epoch 5 is 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = acc\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "a1IDm0KIOBkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980d82b1-3381-4185-82ae-490fdcfa76a3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5695276497695853\n"
          ]
        }
      ]
    }
  ]
}